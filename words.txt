Related words in no particular order

Tensor
    A matrix of >= 3 dimensions.

    https://www.kdnuggets.com/2018/05/wtf-tensor.html
    https://www.youtube.com/watch?v=f5liqUk0ZTw|What's a Tensor?

Input shape
    ?

    https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc

Overfit
    Learning a function that fits the training data very well but does not generalise to other data points.

Bias-variance
    The bias-variance tradeoff also relates to model generalization. In any model, there is a balance between bias, which is
    the constant error term, and variance, which is the amount by which the error may vary between different training sets.
    So, high bias and low variance would be a model that is consistently wrong 20% of the time, whereas a low bias and high
    variance model would be a model that can be wrong anywhere from 5%-50% of the time, depending on the data used to train
    it.

    https://www.kdnuggets.com/2018/04/supervised-vs-unsupervised-learning.html

Class
    A label, category, type.

Filtering
    ?

Convolution
    ?

Pooling
    ?

Rectified linear unit (Relu)
    ?

Neural network
    Convolutional neural network (CNN)
        Good for spatial problems where points closer to one another are more related eg. images.

        https://www.kdnuggets.com/2016/08/brohrer-convolutional-neural-networks-explanation.html

    Feed forward neural network (FNN)
        ?

    Recurrent neural network (RNN)
        ?

Learning
    Shallow learning
        ?

    Deep learning
        A neural network with at least one hidden layer.

        https://github.com/yosinski/deep-visualization-toolbox
        https://www.youtube.com/watch?v=Q9Z20HCPnww|Deep Visualization Toolbox
        https://www.youtube.com/watch?v=AgkfIQ4IGaM|Deep Learning Demystified

    Supervised learning
        Training a model given input values with their respective output values. Learn a function that best approximates
        the relationship between input and output observable in the data.

        https://www.kdnuggets.com/2018/04/supervised-vs-unsupervised-learning.html

    Unsupervised learning
        Does not have labeled outputs. The goal is to infer the natural structure present within a set of data points.

    Reinforcement learning
        ?

Normalisation
    Transforming features to use a similar scale.

    Larger numbers are considered more important(?). If feature A has a range 1-10 and feature B has range 100-1000 then
    feature B may be given more importance due to its larger values. Normalisation puts both feature A and B on the same
    scale.

    https://developers.google.com/machine-learning/data-prep/transform/normalization/
    https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029

Backpropagation
    ?

Model
    A statistical representation of a prediction task. You train a model on examples then use the model to make predictions.

    Sequential model
        A linear stack of layers.

        https://keras.io/getting-started/sequential-model-guide/
        https://jovianlin.io/keras-models-sequential-vs-functional/

    Functional model
        Layers can connect to more than just the previous the next layer. Layers can be connected to any other layer.

        https://keras.io/getting-started/functional-api-guide/

Layer
    Dense layer
        Topology. Describes how the neurons are connected to the next layer of neurons (every neuron is connected to every
        neuron in the next layer). A fully connected layer. A linear operation in which every input is connected to every
        output by a weight.

        https://keras.io/layers/core/#dense

    Convolutional layer
        ?

    Pooling layer
        ?

    Normalisation layer
        Performs Normalisation.

    Flatten layer
        Reduce a tensor to a single dimension.

- Logistic regression
- Linear regression
- Gradient of descent
- One-hit encoding
- Sigmoid activation
- Weights
- Linear softmax
- Feed forward network
- Recurrent neural network
- Unsupervised neural network
- Regularizer
- Optimizer
- Loss
- Categorical cross entropy
- Bias
- Batch learning
- Full batch
- Accuracy matrix
- Trainable parameters
- Epoch
- Convolutions
- Alpha-beta pruning
- Depth-limited
- Minimax
- Adversarial search
- A\* search
- Greedy best first search
- Uninformed search
- Breadth first search
- Depth first search
- Monte carlo tree search
- Genetic algorithm
- Markov decision process
- Q-learning
- Agent
- Node
- State
- Frontier
- Initial state
- Actions
- Transition model
- State space
- Goal test
- Path cost
- Terminal state
- Evaluation function
- Training
- Imperfect information